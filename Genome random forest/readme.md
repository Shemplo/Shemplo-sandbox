## Random forest classifier for genome dataset GSE3189

### Структура проекта
```java
+ src                               // Корень проекта, который содержит все исходники и необходимые ресурсы
|
+-+ main
  |
  +-+ java                          // Исходный код классификатора на Java
  | |
  | +-+ ru.hemplo.genome.rf         // Основной пакет приложения, который содержит в себе класс с главным методом
  |   |                             // Для работы приложения достаточно вызвать метод RunRandomForest.main (...);
  |   +-- data                      // Классы, необходимые для модельного представления данных
  |   |                             // В том числе здесь нормализованная по каждому гену матрица (NormalizedMatrix) 
  |   +-- forest                    // Класс RandomFforest, который содержит в себе множество DecisionTree
  |                                 // И ещё несколько стратегий определения гена (параметра), 
  |                                 // по которому производить деление
  +-+ resources                     // Директория со вспомогательными ресурсами для ограничения используемых генов
    |
    +-- de.csv                      // Файл с сопоставлением генов и протеинов `204130_at` -> `HSD11B2`, ... 
    |                               // Если для какого-то гена не нашлось преобразования, то такой ген забывается
    +-- interactions.txt            // Граф в ребёрной нотации с описанием взаимодействий между протеинами 
                                    // Пример: `PAK1 -- ERBB2`, `SMAD1 -- FOXG1`, ...
    
+ Snowball // вспомогательная библиотека от @Shemplo, которая не является архитипом maven и подключается вручную
```

#### О зависимостях

Все неободимые зависимости (кроме одной) описаны в `pom.xml` и подтягиваются автоматически при сборке проекта

Так же для упрощается используется процессор аннотаций [Project Lombok](https://projectlombok.org), 
который требует патча IDE для работы

### Запуск проекта

Идейная команда запуска:

> java -cp ... -ea ru.shemplo.genome.rf.RunRandomForest GSE3189_series_matrix.txt

Если все необходимые зависимости (описанные выше) установлены, то достаточно запустить 
`main` метод в классе `ru.shemplo.genome.rf.RunRandomForest`. 
После запуска он прочитает файл, переданный ему в качестве аргумента, который содержит
информацию, необходимую для обучения Random Forest'а (в данном случае это dataset GSE3189).

Для того, чтобы лес обучался на тех же данных, которые использует [mcmc ranking](https://github.com/ctlab/mcmcRanking), 
применяется 2-этапная фильтрация входных данных из файла `GSE3189_series_matrix.txt`:
1. Используется файл из ресурсов `de.csv`, который содержит отображение имени гена в имя протеина, 
за который он отвечает. Если для какого-то гена не нашлось такого отображения, то такой ген для
текущего запуска считается забытым и не используется больше нигде.
2. Так как **mcmc ranking** для совей работы использует граф взаимодействия протеинов, описанный в 
`interactions.txt`, то вторая фильтрация выкидывает из списка используемых генов все, которые ни разу
не в стретились в графе (ну точнее, если их протеины ни разу не встретились, ЛИБО если втретилась
запись типа `A -- A` и больше записей с `А` не было).

### Обучение модели

Обучение модели происходит в несколько этапов:

1. В виду того, что горизонтально (по количеству объектов классификации в примере) мало объектов, 
применяется идея `Bagging`'а, которая заключается в том, что множество входных данных 
(которые можно представить в виде матрицы) делится на несколько миноров и очередное дерево использует
для обучения данные только из такого минора. Доказано, что, если так делать несколько раз и при этом
ещё переставлять местами строки и столбцы, то получится "хороший" классификатор. 
В нашем случае происходит деление и переставление только строк (генов), то есть множество носителей
всё время остаётся одним и тем же для всех деревьев. Параметр, который отвчает за кол-во таких полос
при разбиении матрицы передаётся в конструктор объекта `new RandomForest (.., .., .., parts, trees)`. 
Следующий за ним параметр (`trees`) отвечает за то, сколько всего деревьев будет обучено 
(каждый раз, когда все полосы используются, то строки матрицы (с генами) рандомно перемешиваются
и процесс разбиения начинается заново (например, если 20 полос, но надо 21 дево)).

2. Каждое дерево имеет множество генов, которые задают некоторое пространство, которое надо разделить.
На каждом уровне дерево использует стратегию разделения (`SplitStrategy`), которая из всех генов
выбирает тот, по которому достигается наилучшее разделение (например, если средние значения у разных
классов сильно выражены и достаточно удалены друг от друга). При этом высота дерева ограничивается 
неизменяемым параметром, равным 9. 
На новом уровне ген, который был раньше больше использоваться не может 
(при этом один и тот же ген может использоваться в разных ветках дерева).

### Результат работы

После обучения модели, выводится статистика по генам (протеинам), 
которые были выбраны в качесте разделющих хотя бы 1 раз:
при этом вводится метрика квадратичного штрафа для даждого уровня.
Т.е. `score`, который ген получает в дереве зависит от того, на какой глубине этого дерева был использован этот ген.
Для упрощения понимания формула выглядит примерно так: `score = (9 - gene.depth) ^ 2`, после этого для каждого гена
подсчитывается сумма по всем деревьям в лесу.

**Пример:**
если у гена `score == 81`, это значит, что он в 1 дереве был в корневой вершине.
